version: '3.8'

services:
  # --- Orchestration Layer ---
  postgres:
    image: postgres:16
    container_name: mcn_postgres
    restart: always
    environment:
      - POSTGRES_USER=n8n
      - POSTGRES_PASSWORD=n8n_password
      - POSTGRES_DB=n8n
    volumes:
      - ./postgres:/var/lib/postgresql/data
    networks:
      - mcn_network

  redis:
    image: redis:7-alpine
    container_name: mcn_redis
    restart: always
    command: redis-server --appendonly yes --requirepass 123456
    volumes:
      - ./redis:/data
    ports:
      - "6379:6379"
    networks:
      - mcn_network

  # --- Database Layer (MediaCrawlerPro) ---
  mysql:
    image: mysql:8.0
    container_name: mcn_mysql
    restart: always
    environment:
      - MYSQL_ROOT_PASSWORD=123456
      - MYSQL_DATABASE=media_crawler_pro
    command: --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci
    volumes:
      - ./mysql:/var/lib/mysql
    ports:
      - "3306:3306"
    networks:
      - mcn_network

  n8n:
    image: n8nio/n8n:latest
    container_name: mcn_n8n
    restart: always
    environment:
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres
      - DB_POSTGRESDB_PORT=5432
      - DB_POSTGRESDB_DATABASE=n8n
      - DB_POSTGRESDB_USER=n8n
      - DB_POSTGRESDB_PASSWORD=n8n_password
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=admin
      - N8N_BASIC_AUTH_PASSWORD=admin
      - N8N_HOST=localhost
      - N8N_PORT=5678
      - N8N_PROTOCOL=http
      - NODE_ENV=production
      - WEBHOOK_URL=http://localhost:5678/
      # Timezone
      - GENERIC_TIMEZONE=Asia/Shanghai
      # Allow env var access in expressions
      - N8N_BLOCK_ENV_ACCESS_IN_NODE=false
      # Whitelist env vars for task runners (n8n v2.0+)
      - N8N_RUNNERS_TASK_ENV_ALLOW_LIST=SANITY_PROJECT_ID,SANITY_API_TOKEN,DEEPSEEK_API_KEY
      # Sanity CMS
      - SANITY_PROJECT_ID=4t6f8tmh
      - SANITY_API_TOKEN=skNfoTE6nT4cO7t9jj1fRtqL86MJyXKCvLpUWut3q0y1oZQwnQEHz5og38NrYtw7qj5VAeUgSGvDxQmVcgqJzzXrtdwfUrDLtF8GSr4MQ00DJLsTdNmfgkHjmynoiPqrUPEAWeBbIf2bsHS5fezjBqUnnwjMtzQmCcxmCOsVsNFTAE5kBvXP
      # DeepSeek AI
      - DEEPSEEK_API_KEY=sk-4756665d490f43d59223ab9567be34c8
      # n8n v2.0+ File Access Allowlist (semicolon-separated, NOT colons)
      # Required for readWriteFile node to write to custom mount paths
      - N8N_RESTRICT_FILE_ACCESS_TO=/home/node/.n8n;/opt/mcn/assets;/tmp
    ports:
      - "5678:5678"
    volumes:
      - ./n8n:/home/node/.n8n
      - ./assets:/opt/mcn/assets # Unified Asset Path
    depends_on:
      - postgres
      - redis
    networks:
      - mcn_network

  # --- MCN Core Layer (The Citadel) ---
  mcn-core:
    build:
      context: .
      dockerfile: docker/mcn-core.Dockerfile
    container_name: mcn_core
    restart: unless-stopped
    ports:
      - "8000:8000"
    env_file:
      - ./external/BettaFish/.env
      - ./middleware/.env
    environment:
      # Docker Infrastructure Overrides (Highest Priority)
      - MYSQL_HOST=mysql
      - REDIS_URL=redis://:123456@redis:6379/0
      - CRAWLER_URL=http://mediacrawler:8001
      - PYTHONUNBUFFERED=1
    volumes:
      # Code Hot-Reload: Host edits reflect instantly
      - ./middleware:/app/middleware
      - ./external/BettaFish:/app/external/BettaFish
      - ./external/Vidi:/app/external/Vidi
      # Shared Data (Bind Mounts)
      - /mnt/data_ssd/mcn/reports:/app/reports
    shm_size: '2gb'
    depends_on:
      - mysql
      - redis
      - signsrv
    networks:
      - mcn_network

  # --- Signature Server (XHS/Douyin) ---
  signsrv:
    build: ./external/MediaCrawlerPro-SignSrv
    container_name: mcn_signsrv
    restart: unless-stopped
    ports:
      - "8989:8989"
    shm_size: '2gb'
    networks:
      - mcn_network

  # --- Media Crawler Container ---
  mediacrawler:
    build: ./external/MediaCrawlerPro-Python
    container_name: mcn_mediacrawler
    restart: unless-stopped
    ports:
      - "8001:8000"
    environment:
      # MediaCrawlerPro uses RELATION_DB_* for MySQL and REDIS_DB_* for Redis
      - RELATION_DB_HOST=mysql
      - RELATION_DB_PORT=3306
      - RELATION_DB_USER=root
      - RELATION_DB_PWD=123456
      - RELATION_DB_NAME=media_crawler_pro
      - REDIS_DB_HOST=redis
      - REDIS_DB_PORT=6379
      - REDIS_DB_PWD=123456
      # SignSrv connection (uses config.SIGN_SRV_HOST)
      - SIGN_SRV_HOST=signsrv
      - SIGN_SRV_PORT=8989
    volumes:
      - ./external/MediaCrawlerPro-Python:/app
    shm_size: '2gb'
    depends_on:
      - mysql
      - redis
      - signsrv
    networks:
      - mcn_network

  # --- Audio Layer (Phase 1.2) ---
  cosyvoice:
    image: cosyvoice:v3-vpn
    container_name: mcn_cosyvoice
    restart: always
    ports:
      - "50000:50000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
    volumes:
      # Mount models directory (reuse existing models, don't bake into image)
      - ./assets/pretrained_models:/models:ro
      # Cache for modelscope downloads (wetext, etc.)
      - cosyvoice_cache:/root/.cache/modelscope
    environment:
      - CUDA_VISIBLE_DEVICES=0
    # Host IPC for better GPU memory sharing (prevents UVM issues)
    ipc: host
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:50000/docs" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - mcn_network

  # --- Asset Layer (Phase 8) ---
  asset-server:
    image: nginx:alpine
    container_name: mcn_asset_server
    restart: always
    ports:
      - "8081:80"
    volumes:
      - ./config/nginx_cors.conf:/etc/nginx/conf.d/default.conf:ro
      - ./assets:/opt/mcn/assets:ro # Unified Asset Path
    networks:
      - mcn_network

  # --- Brain Layer (Phase 8.5) ---

  # üëÇ Whisper - Word-Level Audio Alignment (CPU for VRAM savings)
  whisper:
    image: fedirz/faster-whisper-server:latest-cpu
    container_name: mcn_whisper
    restart: always
    ports:
      - "8083:8000"
    environment:
      - WHISPER__MODEL=medium
      - WHISPER__DEFAULT_LANGUAGE=zh
    volumes:
      - ./assets:/opt/mcn/assets # Unified Asset Path
    networks:
      - mcn_network

  # --- Perception Layer (Phase 10) ---

  # üì° RSSHub - Universal Feed Converter (YouTube/Twitter ‚Üí RSS)
  rsshub:
    image: diygod/rsshub:latest
    container_name: mcn_rsshub
    restart: always
    ports:
      - "1200:1200"
    environment:
      - CACHE_TYPE=redis
      - REDIS_URL=redis://redis:6379/
      # ‚ö†Ô∏è Required for Twitter/YouTube access in China
      # - PROXY_URI=http://your_proxy_ip:port
    depends_on:
      - redis
    networks:
      - mcn_network

  # üëÇ ydl_api_ng - YouTube Info/Subtitle Extraction API
  ytdlp:
    image: totonyus/ydl_api_ng:latest
    container_name: mcn_ytdlp
    restart: always
    ports:
      - "8082:80"
    volumes:
      - ./assets/temp:/app/downloads
    networks:
      - mcn_network

  # üî• Crawl4AI - Open Source Web Scraper (No Auth Required)
  crawl4ai:
    image: unclecode/crawl4ai:latest
    container_name: mcn_crawl4ai
    restart: always
    ports:
      - "3002:11235"
    environment:
      - CRAWL4AI_API_TOKEN=mcn_local_token
      # Proxy for accessing blocked sites (Clash Verge on host)
      - HTTP_PROXY=http://172.17.0.1:7897
      - HTTPS_PROXY=http://172.17.0.1:7897
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - mcn_network

  # --- LLM Layer (Local DeepSeek Fallback) ---
  ollama:
    image: ollama/ollama:latest
    container_name: mcn_ollama
    restart: always
    ports:
      - "11434:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
    volumes:
      - /mnt/data_ssd/ollama:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_KEEP_ALIVE=5m # Keep models warm for 5 min, evict via API when needed
    networks:
      - mcn_network

  # --- Visual Layer (ComfyUI) - Start with: docker-compose --profile art up -d ---
  comfyui:
    image: yanwk/comfyui-boot:latest
    container_name: mcn_comfyui
    restart: unless-stopped
    profiles:
      - art
      - full
    ports:
      - "8188:8188"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
    environment:
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      # Bind mount from SSD for models and outputs
      - /mnt/data_ssd/ComfyUI/models:/app/ComfyUI/models
      - /mnt/data_ssd/ComfyUI/output:/app/ComfyUI/output
      - /mnt/data_ssd/ComfyUI/custom_nodes:/app/ComfyUI/custom_nodes
    # Per Deep Think: --smart-memory + --cpu-vae to save VRAM
    command: python main.py --listen --port 8188 --smart-memory --cpu-vae
    shm_size: '2gb'
    networks:
      - mcn_network

  # --- Memory Layer (Mem0 Vector Store) ---
  qdrant:
    image: qdrant/qdrant:latest
    container_name: mcn_qdrant
    restart: always
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - ./qdrant_storage:/qdrant/storage
    networks:
      - mcn_network

  # --- Observability Layer ---
  dozzle:
    image: amir20/dozzle:latest
    container_name: mcn_dozzle
    restart: always
    ports:
      - "8888:8080"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - mcn_network

networks:
  mcn_network:
    driver: bridge

volumes:
  cosyvoice_cache:
    driver: local
